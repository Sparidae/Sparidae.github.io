<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/mizuki-favicon-32x32.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/mizuki-favicon-16x16.ico">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-flash.min.css">
  <script src="/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","width":300,"display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="论文笔记：（DIFM）A Dual Input-aware Factorization Machine for CTR Prediction目录2因式分解机fm-factorization-machines3论文的方法our apporach5实验">
<meta property="og:type" content="article">
<meta property="og:title" content="DIFM-用于CTR的双输入感知因子分解机">
<meta property="og:url" content="http://example.com/2022/09/04/%E7%94%A8%E4%BA%8ECTR%E7%9A%84%E5%8F%8C%E8%BE%93%E5%85%A5%E6%84%9F%E7%9F%A5%E5%9B%A0%E5%AD%90%E5%88%86%E8%A7%A3%E6%9C%BA/index.html">
<meta property="og:site_name" content="打工试验场">
<meta property="og:description" content="论文笔记：（DIFM）A Dual Input-aware Factorization Machine for CTR Prediction目录2因式分解机fm-factorization-machines3论文的方法our apporach5实验">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://i.imgur.com/fxzIE4Y.png">
<meta property="og:image" content="https://i.imgur.com/3PUsSqJ.png">
<meta property="og:image" content="https://i.imgur.com/bH1aDSt.png">
<meta property="og:image" content="https://i.imgur.com/zQDSpir.png">
<meta property="og:image" content="https://i.imgur.com/ACkAZ3a.png">
<meta property="og:image" content="https://i.imgur.com/sjbiy6a.png">
<meta property="og:image" content="https://i.imgur.com/c1JEorI.png">
<meta property="article:published_time" content="2022-09-04T07:04:45.000Z">
<meta property="article:modified_time" content="2022-09-27T12:19:54.173Z">
<meta property="article:author" content="Sparidae">
<meta property="article:tag" content="CTR">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.imgur.com/fxzIE4Y.png">

<link rel="canonical" href="http://example.com/2022/09/04/%E7%94%A8%E4%BA%8ECTR%E7%9A%84%E5%8F%8C%E8%BE%93%E5%85%A5%E6%84%9F%E7%9F%A5%E5%9B%A0%E5%AD%90%E5%88%86%E8%A7%A3%E6%9C%BA/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>DIFM-用于CTR的双输入感知因子分解机 | 打工试验场</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">打工试验场</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    <!-- https://cdn.jsdelivr.net/npm/sakana-widget@2.2.2/lib/sakana.min.js -->
<!-- https://cdnjs.cloudflare.com/ajax/libs/sakana-widget/2.2.2/sakana.min.js -->
<!-- 石蒜模拟器代码 -->
<div id="sakana-widget" style="position:fixed;bottom:10px;right:10px;"></div>
<script>
  function initSakanaWidget() {
    new SakanaWidget().mount('#sakana-widget');
  }
</script>
<script
  async
  onload="initSakanaWidget()"
  src="https://cdn.jsdelivr.net/npm/sakana-widget@2.2.2/lib/sakana.min.js"
></script>
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/09/04/%E7%94%A8%E4%BA%8ECTR%E7%9A%84%E5%8F%8C%E8%BE%93%E5%85%A5%E6%84%9F%E7%9F%A5%E5%9B%A0%E5%AD%90%E5%88%86%E8%A7%A3%E6%9C%BA/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://i.imgur.com/gY8RyJm.png">
      <meta itemprop="name" content="Sparidae">
      <meta itemprop="description" content="Great ideals but through selfless struggle and sacrifice to achieve">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="打工试验场">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          DIFM-用于CTR的双输入感知因子分解机
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-09-04 15:04:45" itemprop="dateCreated datePublished" datetime="2022-09-04T15:04:45+08:00">2022-09-04</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-09-27 20:19:54" itemprop="dateModified" datetime="2022-09-27T20:19:54+08:00">2022-09-27</time>
              </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="论文笔记：（DIFM）A-Dual-Input-aware-Factorization-Machine-for-CTR-Prediction"><a href="#论文笔记：（DIFM）A-Dual-Input-aware-Factorization-Machine-for-CTR-Prediction" class="headerlink" title="论文笔记：（DIFM）A Dual Input-aware Factorization Machine for CTR Prediction"></a>论文笔记：（DIFM）A Dual Input-aware Factorization Machine for CTR Prediction</h1><h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><p><a href="#2-因式分解机fm-factorization-machines">2因式分解机fm-factorization-machines</a><br><a href="#3-论文的方法our-apporach">3论文的方法our apporach</a><br><a href="#5实验">5实验</a></p>
<h2 id><a href="#" class="headerlink" title></a><span id="more"></span></h2><h2 id="2-因式分解机FM-Factorization-Machines"><a href="#2-因式分解机FM-Factorization-Machines" class="headerlink" title="2 因式分解机FM Factorization Machines"></a>2 因式分解机FM Factorization Machines</h2><p>作为一类作用于真实值的特征向量的一般的预测因子，因式分解机FM能够有效的预估在显着稀疏性（significant sparsity）下的参数<br>正式的说，FM如下预测目标<br><img src="https://i.imgur.com/fxzIE4Y.png" alt><br>w0是总偏置（bias）<br>wi是标量权重 vi是第i个特征的k维embedding向量</p>
<p><vi,vj>是两个大小为k的向量的点积 是为了给第i个和第j个特征建模</vi,vj></p>
<hr>
<h2 id="3-论文的方法our-apporach"><a href="#3-论文的方法our-apporach" class="headerlink" title="3 论文的方法our apporach"></a>3 论文的方法our apporach</h2><p><img src="https://i.imgur.com/3PUsSqJ.png" alt="模型"></p>
<h3 id="3-1-DIFM模型"><a href="#3-1-DIFM模型" class="headerlink" title="3.1 DIFM模型"></a>3.1 DIFM模型</h3><p>动机是同时在逐位和逐向量的等级 适应性的学习输入感知（inputware）因素,（来对原有的特征表示进行重新加权 比如w和v）</p>
<blockquote>
<p>The motivation is to adaptively learn the input-aware factors<br>(used to reweight the original feature representations: w and v)<br>both at the bit-wise and vector-wise levels simultaneously</p>
</blockquote>
<p>模型包含以下部分<br><a href="#稀疏输入和embedding层">稀疏输入和embedding层</a><br><a href="#双因素预估网络层dual-factor-estimating-networksdual-fen">双因素预估网络层（Dual-Factor Estimating Networks）Dual-FEN</a><br><a href="#连结层-combianationlayer">连结层-combianationlayer</a><br><a href="#重新加权reweighting层">重新加权reweighting层</a><br><a href="#预测层prediction">预测层</a></p>
<h4 id="稀疏输入和embedding层"><a href="#稀疏输入和embedding层" class="headerlink" title="稀疏输入和embedding层"></a>稀疏输入和embedding层</h4><p>这个在基于深度学习的ctr模型中很常用啊，比如DeepFM和AFM<br>稀疏输入对于原始输入特征采用稀疏表示<br>embedding层可以将稀疏特征转化成低维稠密的真值向量<br>embddding层的输出是一个连接（concatenate）的字段向量</p>
<script type="math/tex; mode=display">
E_x=[v_1^T,v_2^T,v_3^T,...,v_i^T,...,v_h^T]</script><p>h是字段的数量 vi代表第i个字段的embedding向量</p>
<h4 id="双因素预估网络层（Dual-Factor-Estimating-Networks）Dual-FEN"><a href="#双因素预估网络层（Dual-Factor-Estimating-Networks）Dual-FEN" class="headerlink" title="双因素预估网络层（Dual-Factor Estimating Networks）Dual-FEN"></a>双因素预估网络层（Dual-Factor Estimating Networks）Dual-FEN</h4><p>包含两个组成成分 the vector-wise part 和 the bit-wise part<br>都是为了学习相同特征在不同输入样例中输入感知的因素</p>
<p><strong>vector-wise</strong><br>灵感来自于transformer在自然语言处理中机器翻译的成功<br>这里采用了他的核心idea <strong>Multi-Head Self-Attention</strong> 在vectorwise等级上学习输入感知因素<br><img src="https://i.imgur.com/bH1aDSt.png" alt></p>
<ol>
<li>首先需要将embedding向量转换成需要的样子 h*k矩阵</li>
<li>然后我们把输入矩阵映射成的三个不同的矩阵，分别是Queries Keys Values 第i个头 或者说第i个子空间（vec 代表vector-wise，bit 代表 bit-wise）<br>$Q_i=U_{vec}W^{Q_i}$<br>$K_i=U_{vec}W^{K_i}$<br>$V_i=U_{vec}W^{V_i}$<br>$d_k$代表注意力因素的大小 </li>
<li>之后我们将Q和K进行点积再除以$\sqrt{d_k}$ 然后使用一个softmax函数来获得对Value的权重<script type="math/tex; mode=display">
Attention(Q_i,K_i,V_i)=softmax(\frac{Q_iK_i^T}{\sqrt{d_k}})V_i</script>之前的论文建议我们使用不同的已学习线性投影将Queries,Keys,Values分别投影到$d_k$,$d_k$,和$d_v$维n次。<br>对所有的投影，我们并行应用attention函数，产生（yielding）一组$d_v$维的向量然后将它们连接（Contanate）起来<script type="math/tex; mode=display">
MultiHead(U_{vec}) = Concat(head_1,...,head_n)</script><script type="math/tex; mode=display">
head_i = Attention(Q_i,K_i,V_i)</script>$head_i\in R^{h\times{d_v}}$代表第i个单头（single head）的输出且n是头的数量</li>
</ol>
<p>为了保存原始embedding向量的信息，在multiheadselfattention处理后，我们使用残差网络（Residual Network）把原先的特征embedding向量，添加到多头自注意的输出中来</p>
<script type="math/tex; mode=display">
Resdual(U_{vec})=Concat(R_1,...,R_n) \\
R_i=U_{vec}W^{R_i}</script><p>最终vectorwise的输出可以这样写</p>
<script type="math/tex; mode=display">O_{vec}=\sigma(Multihead(U_{vec})+Resdual(U_{vec}))</script><p>$\sigma$是激活函数</p>
<p><strong>bit-wise</strong><br>是一堆全连接层<br><img src="https://i.imgur.com/zQDSpir.png" alt><br>输入$I_{bit}=E_x$(the embedding vector)</p>
<script type="math/tex; mode=display">
a_i=\sigma_1(W_1I_{bit}+b_1)\\
...\\
a_i=\sigma_i(W_ia_{i-1}+b_i)\\</script><p>I是输入 W是权重矩阵 b是偏置向量 $\sigma$是激活函数 a是输出</p>
<script type="math/tex; mode=display">O_{bit}=a_L=\sigma_L(W_La_{L-1}+b_L)</script><h4 id="连结层-Combianationlayer"><a href="#连结层-Combianationlayer" class="headerlink" title="连结层 Combianationlayer"></a>连结层 Combianationlayer</h4><p>把vectorwise的向量reshape一下 因为原先vec的输出向量O是$h\times{d_v} \times{n}$的形状 而bit的输出是t的形状</p>
<p>然后这样计算</p>
<script type="math/tex; mode=display">
m_{vec}=O_{vec}P_{vec}\\
m_{bit}=O_{bit}P_{bit}</script><p>P是 将两个O转化为对应的h维向量的 权重矩阵</p>
<p>最后我们结合两个中间的输入感知要素（factor）</p>
<script type="math/tex; mode=display">m_x=m_{vec}+m_{bit}</script><p>$m_x$是和稀疏输入有关的 同时考虑到vec和bit部分的 完全的输入感知因素</p>
<h4 id="重新加权（Reweighting）层"><a href="#重新加权（Reweighting）层" class="headerlink" title="重新加权（Reweighting）层"></a>重新加权（Reweighting）层</h4><p>这层的定义如下</p>
<script type="math/tex; mode=display">
w_{x,i}=m_{x,i}w_i\\
v_{x,i}=m_{x,i}v_i\\</script><p>$m_{x,i}$是$m_x$的第i个元素，对应于x中的每一个非零特征 的 第i个输入感知因素。<br>得到的$w$（reweighted input-aware weight）和$v$（embedding vector）是特定输入特征x的重新加权表示  更准确信息丰富</p>
<h4 id="预测层prediction"><a href="#预测层prediction" class="headerlink" title="预测层prediction"></a>预测层prediction</h4><script type="math/tex; mode=display">
\hat{y}_{DIFM}(x)=w_0+\sum_{i=1}^{n}w_{x,i}x_i +\sum_{i=1}^{n}\sum_{j=i+1}^{n}\left \langle v_{x,i},v_{x,j} \right \rangle x_ix_j</script><h3 id="3-2-学习"><a href="#3-2-学习" class="headerlink" title="3.2 学习"></a>3.2 学习</h3><p>二分类问题<br>采用了对数损失函数</p>
<script type="math/tex; mode=display">
\mathcal{L}=-\frac{1}{N} \sum_{i=1}^{N}\left(y_{i} \log \left(\sigma\left(\hat{y}_{i}\right)\right)+\left(1-y_{i}\right) \log \left(1-\sigma\left(\hat{y}_{i}\right)\right)\right)</script><p>N是训练实例数量</p>
<h3 id="3-3FM和IFM的关系"><a href="#3-3FM和IFM的关系" class="headerlink" title="3.3FM和IFM的关系"></a>3.3FM和IFM的关系</h3><p>如果去掉vector-wise的部分和连结层combianation-layer，DIFM就会变成退化的IFM模型<br>如果我们进一步删除DNN部分（就是bitwise的部分）同时将$m_{x,i}$置成1，那么$w_{x,i}$和$v_{x,i}$就完全依赖于第i个特征，这样DIFM就会退化成传统的FM模型</p>
<hr>
<h2 id="5实验"><a href="#5实验" class="headerlink" title="5实验"></a>5实验</h2><h3 id="5-1实验设置"><a href="#5-1实验设置" class="headerlink" title="5.1实验设置"></a>5.1实验设置</h3><p>使用的是avazu数据集<br>使用和IFM论文一样的处理办法，把数据集分成两个部分0.8训练0.2测试</p>
<p>criteo数据集包含一个月的广告点击数据<br>有13个连续特征和26个种类特征、<br>我们选择连续七天的样本进行训练，然后接下来的一天用来评估<br>最后它包含一个亿数据点击日志的实例</p>
<h4 id="评估指标"><a href="#评估指标" class="headerlink" title="评估指标"></a>评估指标</h4><p>AUC()<br><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/8d9b8e282a53">人工智能通识-科普-AUC和ROC - 简书</a><br>LogLoss(交叉熵)</p>
<blockquote>
<p>Note that an improvement of 0.001-level in AUC or Logloss is usually regarded as being significant for CTR prediction<br>因为在大厂面对的用户基数非常大所以非常小的优化都能带来非常大的利润</p>
</blockquote>
<h4 id="基础"><a href="#基础" class="headerlink" title="基础"></a>基础</h4><ul>
<li>LR逻辑回归</li>
<li>FM用因式分解级数建模二阶特征交互</li>
<li>FFM字段感知embedding向量机制 空间复杂度比较高</li>
<li>NFM导入设置隐藏层数量从1-512个神经元数量</li>
<li>AFM 使用了attention机制区分二阶特征的重要性</li>
<li>DeepFM FM部分是一个因式分解机 deep部分是一个三层MLP层大小分别是256，256，256</li>
<li>xDeepFM 同时考虑了对高阶特征的隐式和显式建模 使用DNN和CIN组件实现</li>
<li>IFM </li>
</ul>
<h4 id="参数设置"><a href="#参数设置" class="headerlink" title="参数设置"></a>参数设置</h4><p>全部使用tensorflow实现<br>为了实现公平比较 所有模型都通过 adam优化损失 学习率全部设置为0.001<br>criteo的embedding大小20 而avazu是40 这和IFM是一样的设置办法<br>每个数据集的batchsize全部设定为2000<br>神经元设定的默认数量DNN是256 CIN是200</p>
<h3 id="5-2超参学习"><a href="#5-2超参学习" class="headerlink" title="5.2超参学习"></a>5.2超参学习</h3><p><img src="https://i.imgur.com/ACkAZ3a.png" alt="网络超参数影响比较"></p>
<p>学习四个超参数</p>
<ol>
<li>attentionhead的数量</li>
<li>attention因素的大小</li>
<li>激活函数</li>
<li>网络深度</li>
</ol>
<p>DIFM中不同组件的作用<br><img src="https://i.imgur.com/sjbiy6a.png" alt></p>
<h3 id="5-3消融学习（abalationstudy）"><a href="#5-3消融学习（abalationstudy）" class="headerlink" title="5.3消融学习（abalationstudy）"></a>5.3消融学习（abalationstudy）</h3><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/Sandwichsauce/article/details/89162570">什么是消融实验 深度学习</a></p>
<h3 id="5-4表现比较"><a href="#5-4表现比较" class="headerlink" title="5.4表现比较"></a>5.4表现比较</h3><p>表现比较<br><img src="https://i.imgur.com/c1JEorI.png" alt></p>

    </div>

    
    
    

    

    
      <div>
        
<div>
    
        <div style="text-align:center;color: #ccc;font-size:12px;">-------------本文结束<i class="fa fa-thumbs-up fa-spin"></i><span class="sr-only">Loading...</span>感谢您的阅读-------------</div>
    
</div>
      </div>
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/CTR/" rel="tag"># CTR</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/09/01/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E5%9F%BA%E7%A1%80%E5%AE%9E%E9%AA%8C/" rel="prev" title="计算机视觉基础实验">
      <i class="fa fa-chevron-left"></i> 计算机视觉基础实验
    </a></div>
      <div class="post-nav-item">
    <a href="/2022/09/07/%E5%8F%94%E6%9C%AC%E5%8D%8E-%E8%AE%BA%E5%85%85%E8%B6%B3%E6%A0%B9%E6%8D%AE%E7%8E%87%E7%9A%84%E5%9B%9B%E9%87%8D%E6%A0%B9/" rel="next" title="叔本华-论充足根据律的四重根">
      叔本华-论充足根据律的四重根 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%EF%BC%9A%EF%BC%88DIFM%EF%BC%89A-Dual-Input-aware-Factorization-Machine-for-CTR-Prediction"><span class="nav-number">1.</span> <span class="nav-text">论文笔记：（DIFM）A Dual Input-aware Factorization Machine for CTR Prediction</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%9B%AE%E5%BD%95"><span class="nav-number">1.1.</span> <span class="nav-text">目录</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">1.2.</span> <span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-%E5%9B%A0%E5%BC%8F%E5%88%86%E8%A7%A3%E6%9C%BAFM-Factorization-Machines"><span class="nav-number">1.3.</span> <span class="nav-text">2 因式分解机FM Factorization Machines</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-%E8%AE%BA%E6%96%87%E7%9A%84%E6%96%B9%E6%B3%95our-apporach"><span class="nav-number">1.4.</span> <span class="nav-text">3 论文的方法our apporach</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-DIFM%E6%A8%A1%E5%9E%8B"><span class="nav-number">1.4.1.</span> <span class="nav-text">3.1 DIFM模型</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%A8%80%E7%96%8F%E8%BE%93%E5%85%A5%E5%92%8Cembedding%E5%B1%82"><span class="nav-number">1.4.1.1.</span> <span class="nav-text">稀疏输入和embedding层</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8F%8C%E5%9B%A0%E7%B4%A0%E9%A2%84%E4%BC%B0%E7%BD%91%E7%BB%9C%E5%B1%82%EF%BC%88Dual-Factor-Estimating-Networks%EF%BC%89Dual-FEN"><span class="nav-number">1.4.1.2.</span> <span class="nav-text">双因素预估网络层（Dual-Factor Estimating Networks）Dual-FEN</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%BF%9E%E7%BB%93%E5%B1%82-Combianationlayer"><span class="nav-number">1.4.1.3.</span> <span class="nav-text">连结层 Combianationlayer</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%87%8D%E6%96%B0%E5%8A%A0%E6%9D%83%EF%BC%88Reweighting%EF%BC%89%E5%B1%82"><span class="nav-number">1.4.1.4.</span> <span class="nav-text">重新加权（Reweighting）层</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%A2%84%E6%B5%8B%E5%B1%82prediction"><span class="nav-number">1.4.1.5.</span> <span class="nav-text">预测层prediction</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-%E5%AD%A6%E4%B9%A0"><span class="nav-number">1.4.2.</span> <span class="nav-text">3.2 学习</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-3FM%E5%92%8CIFM%E7%9A%84%E5%85%B3%E7%B3%BB"><span class="nav-number">1.4.3.</span> <span class="nav-text">3.3FM和IFM的关系</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5%E5%AE%9E%E9%AA%8C"><span class="nav-number">1.5.</span> <span class="nav-text">5实验</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#5-1%E5%AE%9E%E9%AA%8C%E8%AE%BE%E7%BD%AE"><span class="nav-number">1.5.1.</span> <span class="nav-text">5.1实验设置</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87"><span class="nav-number">1.5.1.1.</span> <span class="nav-text">评估指标</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9F%BA%E7%A1%80"><span class="nav-number">1.5.1.2.</span> <span class="nav-text">基础</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8F%82%E6%95%B0%E8%AE%BE%E7%BD%AE"><span class="nav-number">1.5.1.3.</span> <span class="nav-text">参数设置</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-2%E8%B6%85%E5%8F%82%E5%AD%A6%E4%B9%A0"><span class="nav-number">1.5.2.</span> <span class="nav-text">5.2超参学习</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-3%E6%B6%88%E8%9E%8D%E5%AD%A6%E4%B9%A0%EF%BC%88abalationstudy%EF%BC%89"><span class="nav-number">1.5.3.</span> <span class="nav-text">5.3消融学习（abalationstudy）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-4%E8%A1%A8%E7%8E%B0%E6%AF%94%E8%BE%83"><span class="nav-number">1.5.4.</span> <span class="nav-text">5.4表现比较</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Sparidae"
      src="https://i.imgur.com/gY8RyJm.png">
  <p class="site-author-name" itemprop="name">Sparidae</p>
  <div class="site-description" itemprop="description">Great ideals but through selfless struggle and sacrifice to achieve</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">19</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">14</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/Sparidae" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Sparidae" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://steamcommunity.com/id/2992646478/" title="Steam → https:&#x2F;&#x2F;steamcommunity.com&#x2F;id&#x2F;2992646478&#x2F;" rel="noopener" target="_blank"><i class="fab fa-steam fa-fw"></i>Steam</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      友情链接
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://zhengyangwang1.github.io/" title="https:&#x2F;&#x2F;zhengyangWang1.github.io" rel="noopener" target="_blank">陽</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://baidu.com/" title="https:&#x2F;&#x2F;baidu.com" rel="noopener" target="_blank">百度(看不懂请点击)</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://theme-next.iissnan.com/" title="https:&#x2F;&#x2F;theme-next.iissnan.com&#x2F;" rel="noopener" target="_blank">NexT官方文档(?)</a>
        </li>
    </ul>
  </div>

      </div>
      
      <div id="music163player">
        <iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=210 src="//music.163.com/outchain/player?type=0&id=7614540316&auto=0&height=430">
        </iframe>
      </div>
    </div>
  </aside>
  <div id="sidebar-dimmer"></div>
  


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Sparidae</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>




    <script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

    <span id="busuanzi_container_site_pv">总访问量<span id="busuanzi_value_site_pv"></span>次</span>
    <span class="post-meta-divider">|</span>
    <span id="busuanzi_container_site_uv">总访客数<span id="busuanzi_value_site_uv"></span>人</span>
    <span class="post-meta-divider">|</span>
<!-- 不蒜子计数初始值纠正 -->
<script>
$(document).ready(function() {

    var int = setInterval(fixCount, 50);  // 50ms周期检测函数
    var countOffset = 20000;  // 初始化首次数据

    function fixCount() {            
       if (document.getElementById("busuanzi_container_site_pv").style.display != "none")
        {
            $("#busuanzi_value_site_pv").html(parseInt($("#busuanzi_value_site_pv").html()) + countOffset); 
            clearInterval(int);
        }                  
        if ($("#busuanzi_container_site_pv").css("display") != "none")
        {
            $("#busuanzi_value_site_uv").html(parseInt($("#busuanzi_value_site_uv").html()) + countOffset); // 加上初始数据 
            clearInterval(int); // 停止检测
        }  
    }
       	
});
</script> 

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
