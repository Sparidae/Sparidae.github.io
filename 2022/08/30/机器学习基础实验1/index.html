<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-flash.min.css">
  <script src="/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","width":300,"display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="机器学习基础实验目录实验1-1_线性回归实验1-2_K-means聚类">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习基础实验">
<meta property="og:url" content="http://example.com/2022/08/30/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E5%AE%9E%E9%AA%8C1/index.html">
<meta property="og:site_name" content="打工试验场">
<meta property="og:description" content="机器学习基础实验目录实验1-1_线性回归实验1-2_K-means聚类">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://i.imgur.com/IbfDFZ1.png">
<meta property="og:image" content="https://i.imgur.com/TK2YQJJ.png">
<meta property="og:image" content="https://i.imgur.com/euFzxyH.png">
<meta property="og:image" content="https://i.imgur.com/QAN5jF8.png">
<meta property="og:image" content="https://i.imgur.com/QRICVbi.png">
<meta property="og:image" content="https://i.imgur.com/H2HHh8p.png">
<meta property="article:published_time" content="2022-08-30T05:50:14.000Z">
<meta property="article:modified_time" content="2022-09-01T02:22:49.663Z">
<meta property="article:author" content="Sparidae">
<meta property="article:tag" content="机器学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.imgur.com/IbfDFZ1.png">

<link rel="canonical" href="http://example.com/2022/08/30/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E5%AE%9E%E9%AA%8C1/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>机器学习基础实验 | 打工试验场</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">打工试验场</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    <!-- https://cdn.jsdelivr.net/npm/sakana-widget@2.2.2/lib/sakana.min.js -->
<!-- https://cdnjs.cloudflare.com/ajax/libs/sakana-widget/2.2.2/sakana.min.js -->
<div id="sakana-widget"></div>
<script>
  function initSakanaWidget() {
    new SakanaWidget().mount('#sakana-widget');
  }
</script>
<script
  async
  onload="initSakanaWidget()"
  src="https://cdn.jsdelivr.net/npm/sakana-widget@2.2.2/lib/sakana.min.js"
></script>
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/08/30/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E5%AE%9E%E9%AA%8C1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://i.imgur.com/gY8RyJm.png">
      <meta itemprop="name" content="Sparidae">
      <meta itemprop="description" content="Great ideals but through selfless struggle and sacrifice to achieve">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="打工试验场">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          机器学习基础实验
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-08-30 13:50:14" itemprop="dateCreated datePublished" datetime="2022-08-30T13:50:14+08:00">2022-08-30</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-09-01 10:22:49" itemprop="dateModified" datetime="2022-09-01T10:22:49+08:00">2022-09-01</time>
              </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="机器学习基础实验"><a href="#机器学习基础实验" class="headerlink" title="机器学习基础实验"></a>机器学习基础实验</h1><h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><p><a href="#%E5%AE%9E%E9%AA%8C%E7%BC%96%E5%8F%B71-1%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92">实验1-1_线性回归</a><br><a href="">实验1-2_K-means聚类</a></p>
<span id="more"></span>
<hr>
<h2 id="实验编号1-1线性回归"><a href="#实验编号1-1线性回归" class="headerlink" title="实验编号1-1线性回归"></a>实验编号1-1线性回归</h2><h4 id="实验目的"><a href="#实验目的" class="headerlink" title="实验目的"></a>实验目的</h4><ul>
<li>了解线性回归的基本原理</li>
<li>掌握通过梯度下降实现最优解的求解</li>
</ul>
<h4 id="实验步骤："><a href="#实验步骤：" class="headerlink" title="实验步骤："></a>实验步骤：</h4><ol>
<li>生成数据</li>
<li>定义画图函数、假设函数、损失函数、梯度计算函数、参数更新函数</li>
<li>定义线性回归函数，并测试</li>
</ol>
<p>y &#x3D; w*x + b</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_regression</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure>

<p>1、sklearn函数 make_regression()：用来生成回归模型数据。<br>2、参数说明：<br>n_samples：样本数<br>n_features：特征数<br>noise：噪音 <strong>float 数据范围不定 越大数据的偏差越大</strong><br>bias：偏差 不确定的作用<br>3.<br>X : array of shape [n_samples, n_features]<br>y : array of shape [n_samples] or [n_samples, n_targets]<br>4、下面的语句的作用为:生成一组数据集{(x1,y1),(x2,y2),……,(x100,y100)}，后面我们将学习一个线性模型来尽可能的拟合此数据集。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">X, y= make_regression(n_samples=<span class="number">100</span>, n_features=<span class="number">1</span>, noise=<span class="number">14</span>, bias=<span class="number">5</span>)</span><br><span class="line"><span class="built_in">print</span>(X)</span><br><span class="line"><span class="built_in">print</span>(y)</span><br></pre></td></tr></table></figure>

<p>1、自定义函数plotLine()用来画出生成数据集的散点图和拟合线性模型(y&#x3D;k<em>x+b)<br>2、参数说明：<br>theta0:即 y&#x3D;k</em>x+b 中的参数 b<br>theta1:即 y&#x3D;k*x+b 中的参数 k<br>y &#x3D; theta1 *x+theta0<br>X:数据集的横坐标（列表类型）<br>y:数据集的纵坐标（列表类型）<br>3、np.linspace(start, stop, num)函数：用来返回 num 个等间距的样本，在区间[start, stop]中。<br>4、plt.plot(x,y,color,label)：用来画线图<br>参数说明：x:x 轴上的数值；y:y 轴上的数值;color:用来设置线条的颜色，color&#x3D;’r’表示红<br>色(b 表示蓝色)；label 用于指定标签<br>5、plt.scatter(x,y)：用来画散点图。<br>参数说明:<br>x:x 轴上的数值；y:y 轴上的数值。<br>6、plt.axis(）函数用来指定坐标轴的范围。<br>参数需要以列表的形式给出。<br>7、plt.show()：将图像显示出。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">plotLine</span>(<span class="params">theta0, theta1, X, y</span>):</span><br><span class="line">    max_x = np.<span class="built_in">max</span>(X) + <span class="number">100</span> <span class="comment">#np.max(X)用来取出 X 中的最大值</span></span><br><span class="line">    min_x = np.<span class="built_in">min</span>(X) - <span class="number">100</span> <span class="comment">#np.min(X)用来取出 X 中的最小值</span></span><br><span class="line">    xplot = np.linspace(min_x, max_x, <span class="number">1000</span>) <span class="comment">#在区间[min_x,max_x]中返回 1000 个等间隔的样本</span></span><br><span class="line">    yplot = theta0 + theta1 * xplot <span class="comment">#将 x 带入线性方程 y=k*x+b 中求得 y</span></span><br><span class="line">    <span class="built_in">print</span>(theta0) <span class="comment">#打印参数 theta0</span></span><br><span class="line">    <span class="built_in">print</span>(theta1) <span class="comment">#打印参数 theta1</span></span><br><span class="line">    plt.plot(xplot, yplot, color=<span class="string">&#x27;g&#x27;</span>, label=<span class="string">&#x27;Regression Line&#x27;</span>) <span class="comment">#画出线性模型，参数依次表示：横坐标，纵坐标，颜色，标签</span></span><br><span class="line">    plt.scatter(X,y) <span class="comment">#画散点图，参数依次表示横坐标、纵坐标</span></span><br><span class="line">    plt.axis([-<span class="number">5</span>, <span class="number">5</span>, -<span class="number">150</span>, <span class="number">150</span>]) </span><br><span class="line">    <span class="comment">#设置横坐标范围为【-10，10】，纵轴范围为【0，200】调整到可以显示全部数值</span></span><br><span class="line">    plt.show() <span class="comment">#显示可视化图像</span></span><br></pre></td></tr></table></figure>


<p>1、定义一个名为 hypothesis()的函数,根据给定的 x 值预测 y 的值，计算公式为:y&#x3D;theta0 +(theta1*x)<br>计算的是估计值</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">hypothesis</span>(<span class="params">theta0, theta1, x</span>):</span><br><span class="line">    <span class="keyword">return</span> theta0 + (theta1*x)</span><br></pre></td></tr></table></figure>

<p>1、定义一个计算损失值的函数，采用最小二乘法来计算损失。<br>2、zip(x,y)函数用于将可迭代的对象作为参数，将对象中对应的元素打包成一个个元组，然<br>后返回由这些元组组成的列表。<br>譬如：x&#x3D;{x1,x2,x3};y&#x3D;{y1,y2,y3};则 zip(x,y)&#x3D;[(x1,y1),(x2,y2),(x3,y3)]<br>3、y**2:表示 y 的平方。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">cost</span>(<span class="params">theta0, theta1, X, y</span>): <span class="comment">#计算损失</span></span><br><span class="line">    costValue = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> (xi, yi) <span class="keyword">in</span> <span class="built_in">zip</span>(X, y): <span class="comment">#使用 zip()函数，包为元组的列表</span></span><br><span class="line">        costValue += <span class="number">0.5</span> * ((hypothesis(theta0, theta1, xi) - yi)**<span class="number">2</span>) <span class="comment">#使用最小二乘法来计算损失</span></span><br><span class="line">    <span class="keyword">return</span> costValue <span class="comment">#返回损失值</span></span><br></pre></td></tr></table></figure>

<p>1、定义名为 derivatives()的函数，用来计算参数的梯度。<br>2、len()函数：用来返回对象（字符、列表、元组等）长度或项目个数。其参数可以是字符、列表、元组等。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">derivatives</span>(<span class="params">theta0, theta1, X, y</span>): <span class="comment">#derivative:导数</span></span><br><span class="line">    dtheta0 = <span class="number">0</span> <span class="comment">#dtheta0：参数 theta0 的梯度，初始化为 0</span></span><br><span class="line">    dtheta1 = <span class="number">0</span> <span class="comment">#dtheta1：参数 theta1 的梯度，初始化为 0</span></span><br><span class="line">    <span class="keyword">for</span> (xi, yi) <span class="keyword">in</span> <span class="built_in">zip</span>(X, y): <span class="comment">#使用 zip()函数依次取出(xi,yi)</span></span><br><span class="line">        dtheta0 += hypothesis(theta0, theta1, xi) - yi <span class="comment">#计算公式为：损失函数对参数dtheta0 求偏导。</span></span><br><span class="line">        dtheta1 += (hypothesis(theta0, theta1, xi) - yi)*xi <span class="comment">#计算公式为：损失函数对参数dtheta1 求偏导。</span></span><br><span class="line">    dtheta0 /= <span class="built_in">len</span>(X) <span class="comment">#求平均梯度，len(X)函数用来计算 X 中的样本数</span></span><br><span class="line">    dtheta1 /= <span class="built_in">len</span>(X) <span class="comment">#求平均梯度</span></span><br><span class="line">    <span class="keyword">return</span> dtheta0, dtheta1</span><br></pre></td></tr></table></figure>

<p>1、定义一个名为 updateParameters()的函数，用来对参数进行更新。<br>参数说明：<br>theta0 和 theta1 为待更新参数。<br>X、 y 分别表示横轴和纵轴的数值。<br><strong>alpha：学习率 超参</strong>。<br>2、参数的更新：<br>对于参数 w，其更新方式为：w&#x3D;w-学习率*梯度值。其中学习率是一个超参数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">updateParameters</span>(<span class="params">theta0, theta1, X, y, alpha</span>): <span class="comment">#参数的更新，alpha 表示学习率超参</span></span><br><span class="line">    dtheta0, dtheta1 = derivatives(theta0, theta1, X, y) <span class="comment">#dtheta0, dtheta1 分 别 表 示 参 数theta0，theta1 的梯度值。</span></span><br><span class="line">    theta0 = theta0 - (alpha * dtheta0) <span class="comment">#依据参数更新方式更新参数 theta0</span></span><br><span class="line">    theta1 = theta1 - (alpha * dtheta1) <span class="comment">#依据参数更新方式更新参数 theta1</span></span><br><span class="line">    <span class="keyword">return</span> theta0, theta1 <span class="comment">#返回更新好的参数</span></span><br></pre></td></tr></table></figure>

<p>1、定义一个名为 LinearRegression()的线性回归函数。<br>参数说明：<br>X：表示给定数据集的横坐标。<br>y：表示给定数据集的纵坐标。<br>2、np.random.rand()函数:用来返回一个或一组服从“0~1”均匀分布的随机样本值。随机样本取值范围是[0,1)，不包括 1。当不给定参数时，返回的是一个[0，1)区间内的随机数。）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">LinearRegression</span>(<span class="params">X, y</span>):</span><br><span class="line">    theta0 = np.random.rand() <span class="comment">#给 theta0 赋一个随机初始值。</span></span><br><span class="line">    theta1 = np.random.rand() <span class="comment">#给 theta1 赋一个随机初始值。</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">1000</span>): <span class="comment">#进行 1000 次参数的更新，每隔 100 次跟新打印一次图片</span></span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">100</span> == <span class="number">0</span>: <span class="comment">#只有当 i 整除 100 时才进行一次图片打印</span></span><br><span class="line">            plotLine(theta0, theta1, X, y)</span><br><span class="line">            <span class="comment">#print(cost(theta0, theta1, X, y))</span></span><br><span class="line">        theta0, theta1 = updateParameters(theta0, theta1, X, y, <span class="number">0.005</span>) <span class="comment">#调用参数更新函数来对参数进行更新，其中学习率指定为：0.005.</span></span><br><span class="line">LinearRegression(X, y) <span class="comment">#调用线性回归函数</span></span><br></pre></td></tr></table></figure>

<h4 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h4><p><img src="https://i.imgur.com/IbfDFZ1.png" alt="Imgur"><br><img src="https://i.imgur.com/TK2YQJJ.png" alt="Imgur"><br><img src="https://i.imgur.com/euFzxyH.png" alt="Imgur"><br><img src="https://i.imgur.com/QAN5jF8.png" alt="Imgur"><br><img src="https://i.imgur.com/QRICVbi.png" alt="Imgur"></p>
<p>全部代码copy即可 <del>前提是安装了sklearn matplotlib numpy</del></p>
<h2 id="实验1-2-K-means聚类"><a href="#实验1-2-K-means聚类" class="headerlink" title="实验1-2_K-means聚类"></a>实验1-2_K-means聚类</h2><h4 id="实验目的-1"><a href="#实验目的-1" class="headerlink" title="实验目的"></a>实验目的</h4><ul>
<li>了解 K-means 聚类的基本原理</li>
<li>编写程序实现 K-means 聚类方法</li>
</ul>
<h4 id="实验步骤"><a href="#实验步骤" class="headerlink" title="实验步骤"></a>实验步骤</h4><ol>
<li>定义欧式距离函数、类中心选取函数、聚类函数、画图函数</li>
<li>读取待聚类数据完成聚类，并画图观察结果</li>
</ol>
<p><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97%E8%B7%9D%E7%A6%BB">欧几里得距离 - 维基百科，自由的百科全书</a><br>欧式距离函数：<br>参数：<br>vecA, vecB 分别表示两个相同维度的向量，输出结果为两个向量之间的欧氏距离。<br>ndarray相同维度向量类型互相相减等于每个位置相减<br>np.power(array,m): 表示对array中的每个元素求它的m次方,譬如:np.power([0,1,2,3],2)&#x3D;[0,1,4,9]。<br>np.sum(array) 表 示 将 array 中 的 每 个 元 素 相 加 求 和 ， 譬 如 ：np.sum([0,1,2])&#x3D;3,np.sum([[0,1,2],[0,1,2]])&#x3D;6</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">distEclud</span>(<span class="params">vecA, vecB</span>): <span class="comment">#定义一个欧式距离的函数</span></span><br><span class="line">    <span class="keyword">return</span> np.sqrt(np.<span class="built_in">sum</span>(np.power(vecA - vecB, <span class="number">2</span>)))</span><br></pre></td></tr></table></figure>

<p>欧式距离计算示例</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#下面为计算[1,1]和[2,1]之间的欧式距离的一个例子</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;----test_distEclud-----&#x27;</span>)</span><br><span class="line">vecA, vecB = np.array([<span class="number">1</span>,<span class="number">1</span>]),np.array([<span class="number">2</span>,<span class="number">1</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;vecA:&quot;</span>,vecA)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;vecB:&quot;</span>,vecB)</span><br><span class="line">distance = distEclud(vecA, vecB)</span><br><span class="line"><span class="built_in">print</span>(distance) <span class="comment"># 1.0 计算两点之间的距离</span></span><br></pre></td></tr></table></figure>

<p>自定义函数rendCent(dataSet,k)，其中参数dataset为已给数据集，k表示创建中心点的个数</p>
<ul>
<li><p><strong>参数dataSet</strong>形状可以是二维的任意类型矩阵[a,n]<br>  a代表数据坐标的个数<br>  n可以是坐标列的行数 对应第二维 即任意的坐标的维度<br>  可以认为a索引的是对应点的坐标，整个dataset是数据全部坐标的集合</p>
</li>
<li><p><strong>输出centroids</strong>形状是 [k,n]的矩阵<br>  <strong>k</strong>由函数参数给出 代表需要生成点的个数<br>  n对应dataset的n</p>
</li>
<li><p><strong>rendCent进行的操作</strong><br>  取到所有维度的最大值和最小值 每个坐标的维度在这个范围内随机取得 一共取得k个点的坐标</p>
</li>
<li><p><strong>numpy的一些操作</strong><br><strong>np.shape(a)</strong> ：用来查看矩阵或者数组的维度。其中参数 a 为矩阵或者数组，返回值是数据的维度组成的tuple<br><strong>np.zeros([k, n])</strong> ：用来创建一个 k 行 n 列的全 0 数组<br><strong>np.mat(a)</strong> :用于将数组 a 转换为矩阵<br><strong>np.min(a)</strong> :获取数组 a 中的最小值<br><strong>np.max(a)</strong> :获取数组 a 中的最大值<br><strong>np.random.rand(a,b)</strong> :产生一个 a 行 b 列的随机数组，数组中的每个元素为取值为[0,1]之间的随机数</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 随机设置 k 个中心点：</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">randCent</span>(<span class="params">dataSet, k</span>): <span class="comment">#第一个中心点初始化</span></span><br><span class="line">    n = np.shape(dataSet)[<span class="number">1</span>] <span class="comment">#读取矩阵 dataSet 的第二维度的长度</span></span><br><span class="line">    centroids = np.mat(np.zeros([k, n])) <span class="comment">#创建 k 行 n 列的全为 0 的矩阵</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        minj = np.<span class="built_in">min</span>(dataSet[:,j]) <span class="comment">#获得第 j 列的最小值</span></span><br><span class="line">        rangej = <span class="built_in">float</span>(np.<span class="built_in">max</span>(dataSet[:,j]) - minj) <span class="comment">#得到最大值与最小值之间的范围</span></span><br><span class="line">        centroids[:,j] = np.mat(minj + rangej * np.random.rand(k, <span class="number">1</span>)) <span class="comment">#获得输出为 K 行 1列的数据，并且使其在数据集范围内</span></span><br><span class="line">    <span class="keyword">return</span> centroids</span><br></pre></td></tr></table></figure>

<p>这是一个随机中心获取randCent()的例子，其中dataset为[6,2]代表六个二维坐标，r为[2,2]代表两个二维中心点</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;----test_randCent-----&#x27;</span>)</span><br><span class="line">dataSet1 = np.array([[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">6</span>],[<span class="number">8</span>,<span class="number">10</span>],[<span class="number">12</span>,<span class="number">23</span>],[<span class="number">10</span>,<span class="number">11</span>],[<span class="number">13</span>,<span class="number">18</span>]])<span class="comment"># 给出一系列x,y坐标（</span></span><br><span class="line"><span class="built_in">print</span>(dataSet1[<span class="number">1</span>,:])</span><br><span class="line">r = randCent(dataSet1, <span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(r) <span class="comment"># [[ 8.83544015 16.75467081] # [ 2.85688493 4.4799291 ]]</span></span><br></pre></td></tr></table></figure>

<p>导入接下来的实验必要的库</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure>

<ul>
<li>自定义函数 <strong>euclDistance(vector1, vector2)</strong> ，用来计算两个矩阵之间的欧式距离。其中参数</li>
<li><strong>参数vector1, vector2</strong> 分别表示两个矩阵</li>
<li>输出两个矩阵的欧氏距离</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># calculate Euclidean distance</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">euclDistance</span>(<span class="params">vector1, vector2</span>):</span><br><span class="line">    <span class="keyword">return</span> sqrt(<span class="built_in">sum</span>(power(vector2 - vector1, <span class="number">2</span>))) <span class="comment">#求这两个矩阵的距离，vector1、2 均为矩阵</span></span><br></pre></td></tr></table></figure>

<ul>
<li>自定义函数 <strong>initCentroids()</strong> ，用来在样本集中随机抽取k个样本点作为初始质心</li>
<li><strong>参数 dataSet</strong> 为已给数据集，k 表示创建中心点的个数。返回值为所创建的 k 个中心点<br> <strong>np.zeros([k, n])</strong> ：用来创建一个 k 行 n 列的全 0 数组<br> <strong>np.random.uniform(a,b)</strong> :返回区间[a,b)中的任意值<blockquote>
<p>区别于 <strong>np.random.rand(a,b)</strong> :产生一个 a 行 b 列的随机数组，数组中的每个元素为取值为[0,1]之间的随机数</p>
</blockquote>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># init centroids with random samples</span></span><br><span class="line"><span class="comment">#在样本集中随机选取 k 个样本点作为初始质心。</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">initCentroids</span>(<span class="params">dataSet, k</span>):</span><br><span class="line">    numSamples, dim = dataSet.shape <span class="comment">#矩阵的行数、列数，分别代表样例个数元素维度</span></span><br><span class="line">    centroids = zeros((k, dim)) <span class="comment"># 创建一个 k 行 dim 列的全0数组  k是需要产生的数量 dim是数据的维度</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">        index = <span class="built_in">int</span>(random.uniform(<span class="number">0</span>, numSamples)) <span class="comment">#随机产生一个浮点数，然后将其转化为 int 型。</span></span><br><span class="line">        centroids[i, :] = dataSet[index, :] <span class="comment"># 将 dataSet 中 第 index+1 行 赋 值 给centroids 的第 i+1 行。</span></span><br><span class="line">    <span class="keyword">return</span> centroids</span><br></pre></td></tr></table></figure>

<ul>
<li><p>自定义名叫 <strong>kmeans()</strong> 的聚类算法，用于将dataSet矩阵中的样本分成 k 个类</p>
<ul>
<li><strong>参数 dataSet</strong> 为一个矩阵，</li>
<li><strong>参数 k</strong> 表示将分为 k 类</li>
</ul>
</li>
<li><p><strong>聚类（Clustering）</strong><br>是按照某个特定标准(如距离)把一个数据集分割成不同的类或簇，使得同一个簇内的数据对象的相似性尽可能大，同时不在同一个簇中的数据对象的差异性也尽可能地大。也即聚类后同一类的数据尽可能聚集到一起，不同类数据尽量分离。</p>
<ul>
<li><strong>簇</strong> 即种类数量<br><img src="https://i.imgur.com/H2HHh8p.png"></li>
</ul>
</li>
<li><p>numpy的一些操作</p>
<ul>
<li><strong>matrix.A</strong> :将矩阵类型转换为 array 类型<br><strong>需要注意！！</strong> 若matrix的shape是[a,b]，那么即便调用m[:,0].A，返回的数组也是二维的shape为[a,1]的数组</li>
<li><strong>np.nonzero(array)</strong> :用于得到数组 array 中非零元素的位置（数组索引）,参数 array 为一个数组,<br><strong>返回值为一个tuple,其中包含了数组dim数量的元组</strong> ，其中元素分别是array数组的第n个下标组成的数组，方便numpy的整数数组索引</li>
<li><strong>多维数组其实就是以数组做元素的数组</strong><br>所以对一个二维数组做一维索引，其实就是得到一个对应位置的数组</li>
<li><strong>np.mean()</strong> ：求均值。经常操作的参数为 axis，以 m * n 矩阵举例：<br>axis 不设置值，对 m*n 个数求均值，返回一个实数；<br>axis &#x3D; 0：压缩行，对各列求均值，返回 1*n 矩阵；<br>axis &#x3D; 1 ：压缩列，对各行求均值，返回 m*1 矩阵。</li>
</ul>
</li>
<li><p>matplotlib</p>
<ul>
<li><strong>plt.plot(x,y,color,marksize)</strong> :当使用此函数画一个数据点时，参数 x 表示横坐标,参数 y表示纵坐标，参数 color 用来指定点的颜色，参数 marksize 用来指示点的大小</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># k-means cluster</span></span><br><span class="line"><span class="comment">#dataSet 为一个矩阵</span></span><br><span class="line"><span class="comment">#k 为将 dataSet 矩阵中的样本分成 k 个类</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">kmeans</span>(<span class="params">dataSet, k</span>):</span><br><span class="line">    numSamples = dataSet.shape[<span class="number">0</span>] <span class="comment">#读取矩阵 dataSet 的第一维度的长度,即获得有多少个样本数据</span></span><br><span class="line">    clusterAssment = mat(zeros((numSamples, <span class="number">2</span>))) <span class="comment">#得到一个 N*2 的零矩阵,建立簇分配结果矩阵，第一列存类别（minindex），第二列存误差（minDist**2）。</span></span><br><span class="line">    clusterChanged = <span class="literal">True</span> <span class="comment">#用来判断样本聚类结果是否变化的变量。</span></span><br><span class="line">    <span class="comment">## step 1: init centroids</span></span><br><span class="line">    centroids = initCentroids(dataSet, k) <span class="comment">#在样本集中随机选取 k 个样本点作为初始质心</span></span><br><span class="line">    <span class="keyword">while</span> clusterChanged:</span><br><span class="line">        clusterChanged = <span class="literal">False</span><span class="comment">#只有本次运行做出了更改才会变成true</span></span><br><span class="line">        <span class="comment">## for each sample</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(numSamples): <span class="comment">#range</span></span><br><span class="line">            minDist = <span class="number">100000.0</span> <span class="comment">#创建的一个临时变量，用来储存某个样本到所有聚类中心的最小距离。</span></span><br><span class="line">            minIndex = <span class="number">0</span> <span class="comment">#创建的一个临时变量，用来储存和某个样本距离最近的聚类中心的类别作为该样本的类别。</span></span><br><span class="line">            <span class="comment">## for each centroid</span></span><br><span class="line">            <span class="comment">## step 2: find the centroid who is closest</span></span><br><span class="line">            <span class="comment">#计算每个样本点（dataset）与质点（centroid）之间的距离，将其归内到距离最小的那一簇</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">                distance = euclDistance(centroids[j, :], dataSet[i, :]) </span><br><span class="line">                <span class="comment">#计算每个样本到每个聚类中心之间的距离。</span></span><br><span class="line">                <span class="comment"># 第一个索引相当于索引了对应的点</span></span><br><span class="line">                <span class="keyword">if</span> distance &lt; minDist:</span><br><span class="line">                    minDist = distance</span><br><span class="line">                    minIndex = j</span><br><span class="line">            <span class="comment">## step 3: update its cluster</span></span><br><span class="line">            <span class="comment">#k 个簇里面与第 i 个样本距离最小的的标号和距离保存在 clusterAssment中</span></span><br><span class="line">            <span class="comment">#若所有的样本所属类别不在变化，则退出 while 循环</span></span><br><span class="line">            <span class="keyword">if</span> clusterAssment[i, <span class="number">0</span>] != minIndex:</span><br><span class="line">                clusterChanged = <span class="literal">True</span> <span class="comment">#循环条件</span></span><br><span class="line">                clusterAssment[i, :] = minIndex, minDist**<span class="number">2</span> <span class="comment">#两个**表示的是 minDist的平方即误差</span></span><br><span class="line">        <span class="comment">## step 4: update centroids 更新质心</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(k):<span class="comment"># 遍历所有的样本点并更新质心 将均值作为新质心</span></span><br><span class="line">            <span class="comment"># clusterAssment[:,0].A==j 是找出矩阵 clusterAssment 中第一列元素中等于j 的行的下标，</span></span><br><span class="line">            <span class="comment"># 即将所有的原属于j簇的样本点找到</span></span><br><span class="line">            <span class="comment"># 返回的是一个以 array 的列表，第一个 array 为等于 j 的下标</span></span><br><span class="line">            <span class="comment">#!! 将 dataSet矩阵中相对应属于j簇的全部样本提取出来</span></span><br><span class="line">            pointsInCluster = dataSet[nonzero(clusterAssment[:, <span class="number">0</span>].A == j)[<span class="number">0</span>]] </span><br><span class="line">            <span class="comment">#计算标注为 j 的所有样本的平均值并且将值存储进质心</span></span><br><span class="line">            centroids[j, :] = mean(pointsInCluster, axis = <span class="number">0</span>) </span><br><span class="line">    <span class="built_in">print</span> (<span class="string">&#x27;Congratulations, cluster complete!&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> centroids, clusterAssment</span><br></pre></td></tr></table></figure>

<p>画图部分</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># show your cluster only available with 2-D data</span></span><br><span class="line"><span class="comment">#centroids 为 k 个类别，其中保存着每个类别的质心</span></span><br><span class="line"><span class="comment">#clusterAssment 为样本的标记，第一列为此样本的类别号，第二列为到此类别质心的距离</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">showCluster</span>(<span class="params">dataSet, k, centroids, clusterAssment</span>):</span><br><span class="line">    numSamples, dim = dataSet.shape</span><br><span class="line">    <span class="keyword">if</span> dim != <span class="number">2</span>:</span><br><span class="line">        <span class="built_in">print</span> (<span class="string">&quot;Sorry! I can not draw because the dimension of your data is not 2!&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    mark = [<span class="string">&#x27;or&#x27;</span>, <span class="string">&#x27;ob&#x27;</span>, <span class="string">&#x27;og&#x27;</span>, <span class="string">&#x27;ok&#x27;</span>, <span class="string">&#x27;^r&#x27;</span>, <span class="string">&#x27;+r&#x27;</span>, <span class="string">&#x27;sr&#x27;</span>, <span class="string">&#x27;dr&#x27;</span>, <span class="string">&#x27;&lt;r&#x27;</span>, <span class="string">&#x27;pr&#x27;</span>] <span class="comment">#样本颜色</span></span><br><span class="line">    <span class="keyword">if</span> k &gt; <span class="built_in">len</span>(mark):</span><br><span class="line">        <span class="built_in">print</span> (<span class="string">&quot;Sorry! Your k is too large! please contact wojiushimogui&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="comment"># draw all samples</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(numSamples):</span><br><span class="line">        markIndex = <span class="built_in">int</span>(clusterAssment[i, <span class="number">0</span>]) <span class="comment">#为样本指定颜色</span></span><br><span class="line">        plt.plot(dataSet[i, <span class="number">0</span>], dataSet[i, <span class="number">1</span>], mark[markIndex]) <span class="comment">#画出样本</span></span><br><span class="line">    mark = [<span class="string">&#x27;Dr&#x27;</span>, <span class="string">&#x27;Db&#x27;</span>, <span class="string">&#x27;Dg&#x27;</span>, <span class="string">&#x27;Dk&#x27;</span>, <span class="string">&#x27;^b&#x27;</span>, <span class="string">&#x27;+b&#x27;</span>, <span class="string">&#x27;sb&#x27;</span>, <span class="string">&#x27;db&#x27;</span>, <span class="string">&#x27;&lt;b&#x27;</span>, <span class="string">&#x27;pb&#x27;</span>] <span class="comment">#中心的颜色</span></span><br><span class="line">    <span class="comment"># draw the centroids</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">        plt.plot(centroids[i, <span class="number">0</span>], centroids[i, <span class="number">1</span>], mark[i], markersize = <span class="number">12</span>) <span class="comment">#画出中心点</span></span><br><span class="line">    plt.show() <span class="comment">#显示图片</span></span><br></pre></td></tr></table></figure>

<ul>
<li><strong>文件的读取</strong><br><strong>f&#x3D;open(file_path)</strong> #其中 f 叫做文件句柄，file_path 为文件所在的路径。<br><strong>f.readlines()</strong> 函数用来读取文件中的全部内容，返回值为一个列表，列表中的每个元素为每行对应的内容。<br><strong>f.close()</strong> 用来关闭所打开的文件<br><strong>.strip()</strong> 方法用于移除字符串头尾指定的字符（默认为空格或换行符）<br><strong>.split(str)</strong> 方法通过指定分隔符对字符串进行切片，其中参数 str 为分隔符，返回值为一个列表。<br><strong>.append(obj)</strong> 方法用于在列表末尾添加 obj</li>
<li><strong>float(a)</strong> 表示将 a 转化为 float 类型</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">## step 1: 载入待聚类数据</span></span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;step 1: load data...&quot;</span> )</span><br><span class="line">dataSet = [] </span><br><span class="line"><span class="comment">#列表，用来表示，列表中的每个元素也是一个二维的列表；这个二维列表就是一个样本，样本中包含有我们的属性值和类别号。</span></span><br><span class="line"><span class="comment">#与我们所熟悉的矩阵类似，最终我们将获得 N*2 的矩阵，每行元素构成了我们的训练样本的属性值和类别号</span></span><br><span class="line">fileIn = <span class="built_in">open</span>(<span class="string">&quot;testdata.txt&quot;</span>) </span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> fileIn.readlines(): <span class="comment">#依次遍历每一行</span></span><br><span class="line">    temp=[] <span class="comment">#定义一个缓存列表</span></span><br><span class="line">    lineArr = line.strip().split(<span class="string">&#x27;\t&#x27;</span>) <span class="comment">#line.strip()把末尾的&#x27;\n&#x27;去掉，.split(&#x27;\t&#x27;)表示以&#x27;\t&#x27;为分隔符将字符串切片。</span></span><br><span class="line">    temp.append(<span class="built_in">float</span>(lineArr[<span class="number">0</span>])) <span class="comment">#float(a)表示将 a 转化为 float 类型。</span></span><br><span class="line">    temp.append(<span class="built_in">float</span>(lineArr[<span class="number">1</span>]))</span><br><span class="line">    dataSet.append(temp) <span class="comment">#向 dataSet 列表中添加元素。</span></span><br><span class="line">fileIn.close() <span class="comment">#关闭刚刚打开的 testdata.txt 文件。</span></span><br><span class="line"><span class="comment">## step 2: 聚类中... </span></span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;step 2: clustering...&quot;</span> )</span><br><span class="line">dataSet = mat(dataSet) <span class="comment">#mat()函数是 Numpy 中的库函数，将数组转化为矩阵</span></span><br><span class="line">k = <span class="number">4</span></span><br><span class="line">centroids, clusterAssment = kmeans(dataSet, k) <span class="comment">#调用 KMeans 文件中定义的 kmeans 方法</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## step 3: 画图展示结果</span></span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;step 3: show the result...&quot;</span> )</span><br><span class="line">showCluster(dataSet, k, centroids, clusterAssment)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

    </div>

    
    
    

    

    
      <div>
        
<div>
    
        <div style="text-align:center;color: #ccc;font-size:12px;">-------------本文结束<i class="fa fa-thumbs-up fa-spin"></i><span class="sr-only">Loading...</span>感谢您的阅读-------------</div>
    
</div>
      </div>
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"># 机器学习</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/08/30/blog%E6%9B%B4%E6%96%B0log/" rel="prev" title="blog更新log">
      <i class="fa fa-chevron-left"></i> blog更新log
    </a></div>
      <div class="post-nav-item">
    <a href="/2022/08/31/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E5%AE%9E%E9%AA%8C/" rel="next" title="深度学习基础实验">
      深度学习基础实验 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E5%AE%9E%E9%AA%8C"><span class="nav-number">1.</span> <span class="nav-text">机器学习基础实验</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%9B%AE%E5%BD%95"><span class="nav-number">1.1.</span> <span class="nav-text">目录</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AE%9E%E9%AA%8C%E7%BC%96%E5%8F%B71-1%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92"><span class="nav-number">1.2.</span> <span class="nav-text">实验编号1-1线性回归</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AE%9E%E9%AA%8C%E7%9B%AE%E7%9A%84"><span class="nav-number">1.2.0.1.</span> <span class="nav-text">实验目的</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AE%9E%E9%AA%8C%E6%AD%A5%E9%AA%A4%EF%BC%9A"><span class="nav-number">1.2.0.2.</span> <span class="nav-text">实验步骤：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C"><span class="nav-number">1.2.0.3.</span> <span class="nav-text">实验结果</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AE%9E%E9%AA%8C1-2-K-means%E8%81%9A%E7%B1%BB"><span class="nav-number">1.3.</span> <span class="nav-text">实验1-2_K-means聚类</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AE%9E%E9%AA%8C%E7%9B%AE%E7%9A%84-1"><span class="nav-number">1.3.0.1.</span> <span class="nav-text">实验目的</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AE%9E%E9%AA%8C%E6%AD%A5%E9%AA%A4"><span class="nav-number">1.3.0.2.</span> <span class="nav-text">实验步骤</span></a></li></ol></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Sparidae"
      src="https://i.imgur.com/gY8RyJm.png">
  <p class="site-author-name" itemprop="name">Sparidae</p>
  <div class="site-description" itemprop="description">Great ideals but through selfless struggle and sacrifice to achieve</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">6</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/Sparidae" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Sparidae" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://steamcommunity.com/id/2992646478/" title="Steam → https:&#x2F;&#x2F;steamcommunity.com&#x2F;id&#x2F;2992646478&#x2F;" rel="noopener" target="_blank"><i class="fab fa-steam fa-fw"></i>Steam</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      友链
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://zhengyangwang1.github.io/" title="https:&#x2F;&#x2F;zhengyangWang1.github.io" rel="noopener" target="_blank">陽</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://baidu.com/" title="https:&#x2F;&#x2F;baidu.com" rel="noopener" target="_blank">百度(?)</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://theme-next.iissnan.com/" title="https:&#x2F;&#x2F;theme-next.iissnan.com&#x2F;" rel="noopener" target="_blank">NexT官方文档(?)</a>
        </li>
    </ul>
  </div>

      </div>
      
      <div id="music163player">
        <iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=210 src="//music.163.com/outchain/player?type=0&id=7614540316&auto=0&height=430">
        </iframe>
      </div>
    </div>
  </aside>
  <div id="sidebar-dimmer"></div>
  


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Sparidae</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>




    <script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

    <span id="busuanzi_container_site_pv">总访问量<span id="busuanzi_value_site_pv"></span>次</span>
    <span class="post-meta-divider">|</span>
    <span id="busuanzi_container_site_uv">总访客数<span id="busuanzi_value_site_uv"></span>人</span>
    <span class="post-meta-divider">|</span>
<!-- 不蒜子计数初始值纠正 -->
<script>
$(document).ready(function() {

    var int = setInterval(fixCount, 50);  // 50ms周期检测函数
    var countOffset = 20000;  // 初始化首次数据

    function fixCount() {            
       if (document.getElementById("busuanzi_container_site_pv").style.display != "none")
        {
            $("#busuanzi_value_site_pv").html(parseInt($("#busuanzi_value_site_pv").html()) + countOffset); 
            clearInterval(int);
        }                  
        if ($("#busuanzi_container_site_pv").css("display") != "none")
        {
            $("#busuanzi_value_site_uv").html(parseInt($("#busuanzi_value_site_uv").html()) + countOffset); // 加上初始数据 
            clearInterval(int); // 停止检测
        }  
    }
       	
});
</script> 

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
